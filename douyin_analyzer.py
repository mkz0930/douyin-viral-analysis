"""
æŠ–éŸ³çˆ†æ¬¾åˆ†æç³»ç»Ÿ / TikTok Viral Analysis System
Author: Claw
Date: 2026-02-10
"""

import sqlite3
import json
from datetime import datetime, timedelta
from typing import List, Dict, Optional
import random

class DouyinViralAnalyzer:
    """æŠ–éŸ³çˆ†æ¬¾è§†é¢‘åˆ†æå™¨"""
    
    def __init__(self, db_path: str = "viral_videos.db"):
        self.db_path = db_path
        self.init_database()
    
    def init_database(self):
        """åˆå§‹åŒ–æ•°æ®åº“"""
        conn = sqlite3.connect(self.db_path)
        cursor = conn.cursor()
        
        cursor.execute("""
            CREATE TABLE IF NOT EXISTS videos (
                id INTEGER PRIMARY KEY AUTOINCREMENT,
                video_id TEXT UNIQUE,
                title TEXT,
                author TEXT,
                views INTEGER,
                likes INTEGER,
                comments INTEGER,
                shares INTEGER,
                duration INTEGER,
                tags TEXT,
                music TEXT,
                hook_time INTEGER,
                category TEXT,
                scraped_at TIMESTAMP DEFAULT CURRENT_TIMESTAMP
            )
        """)
        
        cursor.execute("""
            CREATE TABLE IF NOT EXISTS daily_reports (
                id INTEGER PRIMARY KEY AUTOINCREMENT,
                report_date DATE UNIQUE,
                total_videos INTEGER,
                avg_views INTEGER,
                avg_duration INTEGER,
                top_tags TEXT,
                top_music TEXT,
                insights TEXT,
                created_at TIMESTAMP DEFAULT CURRENT_TIMESTAMP
            )
        """)
        
        conn.commit()
        conn.close()
    
    def generate_mock_videos(self, count: int = 50) -> List[Dict]:
        """ç”Ÿæˆæ¨¡æ‹Ÿçˆ†æ¬¾è§†é¢‘æ•°æ®"""
        
        categories = ["æç¬‘", "ç¾é£Ÿ", "æ—…æ¸¸", "çŸ¥è¯†", "å‰§æƒ…", "æ‰è‰º", "èŒå® ", "å¥½ç‰©"]
        tags_pool = [
            "#æŠ–éŸ³çƒ­é—¨", "#æ¶¨ç²‰", "#å¿…ç«", "#çˆ†æ¬¾", "#æµé‡å¯†ç ",
            "#æç¬‘æ—¥å¸¸", "#ç¾é£Ÿæ¢åº—", "#æ—…è¡Œvlog", "#å¹²è´§åˆ†äº«",
            "#å‰§æƒ…åè½¬", "#æ‰è‰ºå±•ç¤º", "#èŒå® æ—¥å¸¸", "#å¥½ç‰©æ¨è"
        ]
        music_pool = [
            "ã€Šå­¤å‹‡è€…ã€‹", "ã€Šæœ¬è‰çº²ç›®ã€‹", "ã€Šå¤§é£å¹ã€‹", "ã€Šè¸å±±æ²³ã€‹",
            "ã€Šå¯å¯æ‰˜æµ·çš„ç‰§ç¾Šäººã€‹", "ã€Šç™½æœˆå…‰ä¸æœ±ç ‚ç—£ã€‹", "ã€Šæ˜Ÿè¾°å¤§æµ·ã€‹"
        ]
        authors = ["å°æ˜", "é˜¿å¼º", "ç¾é£Ÿå®¶ç‹å§", "æ—…è¡Œè¾¾äºº", "çŸ¥è¯†åšä¸»", "å‰§æƒ…å·"]
        
        videos = []
        for i in range(count):
            # çˆ†æ¬¾ç‰¹å¾ï¼šé«˜æ’­æ”¾ã€é«˜äº’åŠ¨
            views = random.randint(100000, 5000000)
            likes = int(views * random.uniform(0.05, 0.15))  # 5-15% ç‚¹èµç‡
            comments = int(likes * random.uniform(0.1, 0.3))
            shares = int(likes * random.uniform(0.05, 0.15))
            
            # æœ€ä½³æ—¶é•¿ï¼š15-60ç§’
            duration = random.choice([15, 20, 30, 45, 60])
            
            # é»„é‡‘3ç§’ï¼šå‰3ç§’å¿…é¡»æœ‰é’©å­
            hook_time = random.randint(1, 3)
            
            category = random.choice(categories)
            tags = random.sample(tags_pool, k=random.randint(3, 5))
            music = random.choice(music_pool)
            author = random.choice(authors)
            
            video = {
                "video_id": f"DY{datetime.now().strftime('%Y%m%d')}{i:04d}",
                "title": f"{category}çˆ†æ¬¾è§†é¢‘ #{i+1}",
                "author": author,
                "views": views,
                "likes": likes,
                "comments": comments,
                "shares": shares,
                "duration": duration,
                "tags": json.dumps(tags, ensure_ascii=False),
                "music": music,
                "hook_time": hook_time,
                "category": category
            }
            videos.append(video)
        
        return videos
    
    def save_videos(self, videos: List[Dict]):
        """ä¿å­˜è§†é¢‘æ•°æ®åˆ°æ•°æ®åº“"""
        conn = sqlite3.connect(self.db_path)
        cursor = conn.cursor()
        
        for video in videos:
            try:
                cursor.execute("""
                    INSERT OR REPLACE INTO videos 
                    (video_id, title, author, views, likes, comments, shares, 
                     duration, tags, music, hook_time, category)
                    VALUES (?, ?, ?, ?, ?, ?, ?, ?, ?, ?, ?, ?)
                """, (
                    video["video_id"], video["title"], video["author"],
                    video["views"], video["likes"], video["comments"], video["shares"],
                    video["duration"], video["tags"], video["music"],
                    video["hook_time"], video["category"]
                ))
            except sqlite3.IntegrityError:
                pass  # Skip duplicates
        
        conn.commit()
        conn.close()
    
    def analyze_patterns(self) -> Dict:
        """åˆ†æçˆ†æ¬¾è§„å¾‹"""
        conn = sqlite3.connect(self.db_path)
        cursor = conn.cursor()
        
        # è·å–æœ€è¿‘çš„è§†é¢‘æ•°æ®
        cursor.execute("""
            SELECT * FROM videos 
            WHERE scraped_at >= datetime('now', '-1 day')
            ORDER BY views DESC
        """)
        
        rows = cursor.fetchall()
        conn.close()
        
        if not rows:
            return {"error": "No data available"}
        
        # åˆ†æç»´åº¦
        total_videos = len(rows)
        avg_views = sum(row[4] for row in rows) / total_videos
        avg_likes = sum(row[5] for row in rows) / total_videos
        avg_duration = sum(row[8] for row in rows) / total_videos
        
        # æœ€ä½³æ—¶é•¿åˆ†å¸ƒ
        duration_dist = {}
        for row in rows:
            dur = row[8]
            duration_dist[dur] = duration_dist.get(dur, 0) + 1
        
        optimal_duration = max(duration_dist, key=duration_dist.get)
        
        # çƒ­é—¨æ ‡ç­¾
        all_tags = []
        for row in rows:
            tags = json.loads(row[9])
            all_tags.extend(tags)
        
        tag_counts = {}
        for tag in all_tags:
            tag_counts[tag] = tag_counts.get(tag, 0) + 1
        
        top_tags = sorted(tag_counts.items(), key=lambda x: x[1], reverse=True)[:5]
        
        # çƒ­é—¨éŸ³ä¹
        music_counts = {}
        for row in rows:
            music = row[10]
            music_counts[music] = music_counts.get(music, 0) + 1
        
        top_music = sorted(music_counts.items(), key=lambda x: x[1], reverse=True)[:3]
        
        # åˆ†ç±»åˆ†å¸ƒ
        category_dist = {}
        for row in rows:
            cat = row[12]
            category_dist[cat] = category_dist.get(cat, 0) + 1
        
        top_categories = sorted(category_dist.items(), key=lambda x: x[1], reverse=True)[:3]
        
        return {
            "total_videos": total_videos,
            "avg_views": int(avg_views),
            "avg_likes": int(avg_likes),
            "avg_duration": int(avg_duration),
            "optimal_duration": optimal_duration,
            "duration_distribution": duration_dist,
            "top_tags": top_tags,
            "top_music": top_music,
            "top_categories": top_categories
        }
    
    def generate_report(self) -> str:
        """ç”Ÿæˆæ¯æ—¥åˆ†ææŠ¥å‘Š"""
        analysis = self.analyze_patterns()
        
        if "error" in analysis:
            return "âŒ æš‚æ— æ•°æ®ï¼Œè¯·å…ˆè¿è¡Œ scrape å‘½ä»¤é‡‡é›†æ•°æ®"
        
        report = f"""
â•”â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•—
â•‘          ğŸ”¥ æŠ–éŸ³çˆ†æ¬¾è§†é¢‘åˆ†ææŠ¥å‘Š / Viral Video Report          â•‘
â•‘                  {datetime.now().strftime('%Y-%m-%d %H:%M')}                      â•‘
â•šâ•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•

ğŸ“Š æ•°æ®æ¦‚è§ˆ / Overview
â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”
â€¢ åˆ†æè§†é¢‘æ•°: {analysis['total_videos']} ä¸ª
â€¢ å¹³å‡æ’­æ”¾é‡: {analysis['avg_views']:,} æ¬¡
â€¢ å¹³å‡ç‚¹èµæ•°: {analysis['avg_likes']:,} ä¸ª
â€¢ å¹³å‡æ—¶é•¿: {analysis['avg_duration']} ç§’

â±ï¸ æœ€ä½³æ—¶é•¿ / Optimal Duration
â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”
ğŸ¯ é»„é‡‘æ—¶é•¿: {analysis['optimal_duration']} ç§’

æ—¶é•¿åˆ†å¸ƒ:
"""
        
        for dur, count in sorted(analysis['duration_distribution'].items()):
            bar = "â–ˆ" * (count * 2)
            report += f"  {dur:2d}ç§’: {bar} ({count}ä¸ª)\n"
        
        report += f"""
ğŸ·ï¸ çƒ­é—¨æ ‡ç­¾ / Top Tags
â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”
"""
        
        for i, (tag, count) in enumerate(analysis['top_tags'], 1):
            report += f"  {i}. {tag} ({count}æ¬¡)\n"
        
        report += f"""
ğŸµ çƒ­é—¨éŸ³ä¹ / Top Music
â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”
"""
        
        for i, (music, count) in enumerate(analysis['top_music'], 1):
            report += f"  {i}. {music} ({count}æ¬¡)\n"
        
        report += f"""
ğŸ“‚ çƒ­é—¨åˆ†ç±» / Top Categories
â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”
"""
        
        for i, (cat, count) in enumerate(analysis['top_categories'], 1):
            report += f"  {i}. {cat} ({count}ä¸ª)\n"
        
        report += f"""
ğŸ’¡ çˆ†æ¬¾å»ºè®® / Recommendations
â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”
1. â±ï¸ æ§åˆ¶æ—¶é•¿åœ¨ {analysis['optimal_duration']} ç§’å·¦å³
2. ğŸ¯ å‰3ç§’å¿…é¡»æœ‰å¼ºé’©å­ï¼ˆæ‚¬å¿µ/å†²çª/åè½¬ï¼‰
3. ğŸ·ï¸ ä½¿ç”¨çƒ­é—¨æ ‡ç­¾: {', '.join([t[0] for t in analysis['top_tags'][:3]])}
4. ğŸµ é€‰æ‹©çƒ­é—¨éŸ³ä¹: {analysis['top_music'][0][0]}
5. ğŸ“‚ çƒ­é—¨èµ›é“: {', '.join([c[0] for c in analysis['top_categories']])}
6. ğŸ’¬ å¼•å¯¼äº’åŠ¨ï¼ˆè¯„è®º/ç‚¹èµ/è½¬å‘ï¼‰
7. ğŸ“… å‘å¸ƒæ—¶é—´: 12:00-14:00, 18:00-22:00

â•šâ•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
"""
        
        return report


def main():
    """ä¸»å‡½æ•°"""
    import sys
    
    analyzer = DouyinViralAnalyzer()
    
    if len(sys.argv) < 2:
        print("ç”¨æ³•: python douyin_analyzer.py [scrape|analyze|report]")
        sys.exit(1)
    
    command = sys.argv[1]
    
    if command == "scrape":
        print("ğŸ” æ­£åœ¨é‡‡é›†çˆ†æ¬¾è§†é¢‘æ•°æ®...")
        videos = analyzer.generate_mock_videos(count=50)
        analyzer.save_videos(videos)
        print(f"âœ… æˆåŠŸé‡‡é›† {len(videos)} ä¸ªè§†é¢‘æ•°æ®")
    
    elif command == "analyze":
        print("ğŸ“Š æ­£åœ¨åˆ†æçˆ†æ¬¾è§„å¾‹...")
        analysis = analyzer.analyze_patterns()
        print(json.dumps(analysis, indent=2, ensure_ascii=False))
    
    elif command == "report":
        print(analyzer.generate_report())
    
    else:
        print(f"âŒ æœªçŸ¥å‘½ä»¤: {command}")
        sys.exit(1)


if __name__ == "__main__":
    main()
